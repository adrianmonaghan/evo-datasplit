# evo-datasplit
This is a repo that can containt pretty much any type of evolutionary computing you would like to do. Right now it's single threaded, but there is the possiblity to multi-process it. 
The current example provides a case when you are trying to fairly split data between three splits: train, test, and validation. There is also the case when you have already defined a split and would like to be able to demote from one split to another, for example, demote a dataset from the test set into the validation set if it allows for a fairer split. It will then run for the number of times specified at the bottom of main.py. Main.py also contains the code to create the original data set, the code to score each dataset and the code to display/save the results. It also profiles the code if you're so interested. The way it measures fairness is by calculating the l2 norm of the difference between the target percent split, and the distribution of metadata. For example, If you were looking to have 60% of the data in the training set, the l2-norm finds the percent in the current training split compared to the entire dataset for each meatadata column, subtracts that percent from 0.6, and find the length of the n-dimensional vector of the difference. It does this for all train, test, and validation. It then returns all of the non-dominated best splits. A dominated split is one in which there exists a split which is beaten at least once in every aspect by another split. For example: if we create a split that has an l2-norm of the train, val, and test respectively as 0.4, 0.3, 0.4, and another split that has an l2 of 0.5, 0.35, 0.6, the second split is dominated by the first split and therefore the second split is removed. However, if you have a third split: 0.35, 0.6, 0.9, this split is not dominated by the first split because the train l2-norm is better on the third split, this split or "solution" is kept as a viable solution to the problem. 
